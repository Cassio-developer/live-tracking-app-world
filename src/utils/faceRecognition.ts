// Verificar se face-api.js est√° dispon√≠vel
declare global {
  interface Window {
    faceapi: any;
  }
}

// Importa√ß√£o condicional
let faceapi: any;
try {
  faceapi = require('face-api.js');
} catch (error) {
  console.warn('face-api.js n√£o est√° dispon√≠vel');
}

export interface FaceDetectionResult {
  success: boolean;
  descriptor?: Float32Array;
  landmarks?: any;
  error?: string;
}

export interface FaceComparisonResult {
  isMatch: boolean;
  confidence: number;
  distance: number;
}

export interface FaceSetupResult {
  success: boolean;
  descriptors: Float32Array[];
  error?: string;
}

/**
 * Carrega os modelos necess√°rios para reconhecimento facial
 * @returns Promise<boolean> - true se carregado com sucesso
 */
export const loadFaceModels = async (): Promise<boolean> => {
  console.log('üîÑ loadFaceModels chamada, faceapi dispon√≠vel:', !!faceapi);
  
  if (!faceapi) {
    console.error('‚ùå face-api.js n√£o est√° dispon√≠vel');
    return false;
  }

  try {
    console.log('üîÑ Carregando modelos de reconhecimento facial...');
    
    await Promise.all([
      faceapi.loadTinyFaceDetectorModel('/models'),
      faceapi.loadFaceLandmarkModel('/models'),
      faceapi.loadFaceRecognitionModel('/models')
    ]);
    
    console.log('‚úÖ Modelos carregados com sucesso');
    
    // Verificar se os modelos foram carregados
    const modelsLoaded = faceapi.nets.tinyFaceDetector.isLoaded && 
                        faceapi.nets.faceLandmark68Net.isLoaded && 
                        faceapi.nets.faceRecognitionNet.isLoaded;
    
    console.log('üìä Status dos modelos:', {
      tinyFaceDetector: faceapi.nets.tinyFaceDetector.isLoaded,
      faceLandmark68: faceapi.nets.faceLandmark68Net.isLoaded,
      faceRecognition: faceapi.nets.faceRecognitionNet.isLoaded
    });
    
    return modelsLoaded;
  } catch (error) {
    console.error('‚ùå Erro ao carregar modelos:', error);
    return false;
  }
};

/**
 * Inicia o stream de v√≠deo da c√¢mera
 * @param videoElement - Elemento de v√≠deo HTML
 * @param options - Op√ß√µes de configura√ß√£o da c√¢mera
 * @returns Promise<MediaStream | null>
 */
export const startVideoStream = async (
  videoElement: HTMLVideoElement,
  options: MediaStreamConstraints = {
    video: {
      width: { ideal: 640 },
      height: { ideal: 480 },
      facingMode: 'user'
    }
  }
): Promise<MediaStream | null> => {
  try {
    const stream = await navigator.mediaDevices.getUserMedia(options);
    videoElement.srcObject = stream;
    await videoElement.play();
    
    console.log('‚úÖ Stream de v√≠deo iniciado');
    return stream;
  } catch (error) {
    console.error('‚ùå Erro ao iniciar stream de v√≠deo:', error);
    return null;
  }
};

/**
 * Detecta face em um elemento de v√≠deo
 * @param videoElement - Elemento de v√≠deo HTML
 * @returns Promise<FaceDetectionResult>
 */
export const detectFace = async (videoElement: HTMLVideoElement): Promise<FaceDetectionResult> => {
  console.log('üîç detectFace chamada, faceapi dispon√≠vel:', !!faceapi);
  
  if (!faceapi) {
    console.log('‚ùå face-api.js n√£o est√° dispon√≠vel');
    return {
      success: false,
      error: 'face-api.js n√£o est√° dispon√≠vel'
    };
  }

  try {
    if (!videoElement.videoWidth || !videoElement.videoHeight) {
      console.log('‚ùå V√≠deo n√£o est√° pronto:', { width: videoElement.videoWidth, height: videoElement.videoHeight });
      return {
        success: false,
        error: 'V√≠deo n√£o est√° pronto'
      };
    }

    console.log('üîç Tentando detectar face...', { width: videoElement.videoWidth, height: videoElement.videoHeight });

    const detection = await faceapi.detectSingleFace(
      videoElement,
      new faceapi.TinyFaceDetectorOptions({
        inputSize: 224,
        scoreThreshold: 0.3 // Reduzido para ser mais sens√≠vel
      })
    ).withFaceLandmarks().withFaceDescriptor();

    if (detection) {
      console.log('‚úÖ Face detectada com sucesso!');
      return {
        success: true,
        descriptor: detection.descriptor,
        landmarks: detection.landmarks
      };
    } else {
      console.log('‚ùå Nenhuma face detectada');
      return {
        success: false,
        error: 'Nenhuma face detectada'
      };
    }
  } catch (error) {
    console.error('‚ùå Erro na detec√ß√£o facial:', error);
    return {
      success: false,
      error: 'Erro na detec√ß√£o facial'
    };
  }
};

/**
 * Compara dois descritores faciais
 * @param descriptor1 - Primeiro descritor facial
 * @param descriptor2 - Segundo descritor facial
 * @param threshold - Limiar de similaridade (padr√£o: 0.6)
 * @returns FaceComparisonResult
 */
export const compareFaces = (
  descriptor1: Float32Array,
  descriptor2: Float32Array,
  threshold: number = 0.6
): FaceComparisonResult => {
  if (!faceapi) {
    return {
      isMatch: false,
      confidence: 0,
      distance: Infinity
    };
  }

  try {
    const distance = faceapi.euclideanDistance(descriptor1, descriptor2);
    const isMatch = distance < threshold;
    const confidence = Math.max(0, 1 - distance);

    return {
      isMatch,
      confidence,
      distance
    };
  } catch (error) {
    console.error('‚ùå Erro na compara√ß√£o facial:', error);
    return {
      isMatch: false,
      confidence: 0,
      distance: Infinity
    };
  }
};

/**
 * Captura m√∫ltiplas amostras faciais para registro
 * @param videoElement - Elemento de v√≠deo HTML
 * @param sampleCount - N√∫mero de amostras (padr√£o: 5)
 * @param intervalMs - Intervalo entre capturas (padr√£o: 1000ms)
 * @returns Promise<FaceSetupResult>
 */
export const captureFaceSamples = async (
  videoElement: HTMLVideoElement,
  sampleCount: number = 5,
  intervalMs: number = 1000
): Promise<FaceSetupResult> => {
  try {
    const descriptors: Float32Array[] = [];
    
    console.log(`üîÑ Capturando ${sampleCount} amostras faciais...`);
    
    for (let i = 0; i < sampleCount; i++) {
      const detection = await detectFace(videoElement);
      
      if (detection.success && detection.descriptor) {
        descriptors.push(detection.descriptor);
        console.log(`‚úÖ Amostra ${i + 1}/${sampleCount} capturada`);
        
        if (i < sampleCount - 1) {
          await new Promise(resolve => setTimeout(resolve, intervalMs));
        }
      } else {
        console.warn(`‚ö†Ô∏è Falha na captura da amostra ${i + 1}`);
      }
    }
    
    if (descriptors.length >= Math.ceil(sampleCount * 0.8)) {
      return {
        success: true,
        descriptors
      };
    } else {
      return {
        success: false,
        descriptors: [],
        error: 'Poucas amostras v√°lidas capturadas'
      };
    }
  } catch (error) {
    console.error('‚ùå Erro na captura de amostras:', error);
    return {
      success: false,
      descriptors: [],
      error: 'Erro na captura de amostras'
    };
  }
};

/**
 * Desenha landmarks faciais em um canvas
 * @param canvas - Elemento canvas HTML
 * @param detection - Resultado da detec√ß√£o facial
 * @param displaySize - Tamanho de exibi√ß√£o
 */
export const drawFaceLandmarks = (
  canvas: HTMLCanvasElement,
  detection: FaceDetectionResult,
  displaySize: { width: number; height: number }
): void => {
  if (!faceapi || !detection.landmarks) return;

  try {
    const ctx = canvas.getContext('2d');
    if (!ctx) return;
    
    // Limpar canvas
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    
    // Redimensionar detec√ß√£o para o tamanho de exibi√ß√£o
    const resizedDetection = faceapi.resizeResults(
      { landmarks: detection.landmarks },
      displaySize
    );
    
    // Desenhar landmarks
    faceapi.draw.drawFaceLandmarks(canvas, [resizedDetection]);
  } catch (error) {
    console.error('‚ùå Erro ao desenhar landmarks:', error);
  }
};

/**
 * Verifica se o dispositivo suporta reconhecimento facial
 * @returns boolean
 */
export const isFaceRecognitionSupported = (): boolean => {
  return !!(
    navigator.mediaDevices &&
    navigator.mediaDevices.getUserMedia
  );
};

/**
 * Para o stream de v√≠deo
 * @param stream - Stream de m√≠dia
 */
export const stopVideoStream = (stream: MediaStream | null): void => {
  if (stream) {
    stream.getTracks().forEach(track => track.stop());
    console.log('üõë Stream de v√≠deo parado');
  }
}; 